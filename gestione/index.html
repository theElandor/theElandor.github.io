<!DOCTYPE html>
<html lang="en">
<head>
  
    <title>Gestione dell&#39;informazione ITA-(2022/2023) :: ML</title>
  
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="description" content="gestione dell&#39;informazione" />
<meta name="keywords" content="" />
<meta name="robots" content="noodp" />
<link rel="canonical" href="/gestione/" />




<link rel="stylesheet" href="/assets/style.css">

  <link rel="stylesheet" href="/assets/blue.css">



<link rel="stylesheet" href="/style.css">


<link rel="apple-touch-icon" href="/img/apple-touch-icon-192x192.png">

  <link rel="shortcut icon" href="/img/favicon/blue.png">



<meta name="twitter:card" content="summary" />

  
    <meta name="twitter:site" content="" />
  
    <meta name="twitter:creator" content="" />



<meta property="og:locale" content="en" />
<meta property="og:type" content="article" />
<meta property="og:title" content="Gestione dell&#39;informazione ITA-(2022/2023)">
<meta property="og:description" content="gestione dell&#39;informazione" />
<meta property="og:url" content="/gestione/" />
<meta property="og:site_name" content="ML" />

  
    <meta property="og:image" content="/img/favicon/blue.png">
  

<meta property="og:image:width" content="2048">
<meta property="og:image:height" content="1024">


  <meta property="article:published_time" content="2022-10-14 16:59:34 &#43;0200 CEST" />









<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML' async></script>
<script src="/mathjax-config.js"></script>


</head>
<body class="blue">


<div class="container center headings--one-size">

  <header class="header">
  <div class="header__inner">
    <div class="header__logo">
      <a href="/">
  <div class="logo">
    Home
  </div>
</a>

    </div>
    
      <div class="menu-trigger">menu</div>
    
  </div>
  
    <nav class="menu">
  <ul class="menu__inner menu__inner--desktop">
    
      
        
          <li><a href="/about">About</a></li>
        
      
        
          <li><a href="/htb">HTB</a></li>
        
      
      
        <ul class="menu__sub-inner">
          <li class="menu__sub-inner-more-trigger">Uni-Notes ▾</li>

          <ul class="menu__sub-inner-more hidden">
            
              
                <li><a href="/gestione">Inform. Retrieval</a></li>
              
            
              
                <li><a href="/compilatori">Linguaggi e Compilatori</a></li>
              
            
              
                <li><a href="/reti">Reti</a></li>
              
            
              
                <li><a href="/security">Security</a></li>
              
            
          </ul>
        </ul>
      
    

    
  </ul>

  <ul class="menu__inner menu__inner--mobile">
    
      
        <li><a href="/about">About</a></li>
      
    
      
        <li><a href="/htb">HTB</a></li>
      
    
      
        <li><a href="/gestione">Inform. Retrieval</a></li>
      
    
      
        <li><a href="/compilatori">Linguaggi e Compilatori</a></li>
      
    
      
        <li><a href="/reti">Reti</a></li>
      
    
      
        <li><a href="/security">Security</a></li>
      
    
    
  </ul>
</nav>

  
</header>


  <div class="content">
    
<div class="post">
  <h1 class="post-title">
    <a href="/gestione/">Gestione dell&rsquo;informazione ITA-(2022/2023)</a></h1>
  <div class="post-meta">
    
      <span class="post-date">
        2022-10-14
        
      </span>
    
    
    
  </div>

  
  


  

  <div class="post-content"><div>
        <h2 id="disclaimer"><em>Disclaimer</em><a href="#disclaimer" class="hanchor" ariaLabel="Anchor">&#8983;</a> </h2>
<pre><code class="language-example" data-lang="example">Questa pagina (in italiano) contiene i miei appunti del corso di
&quot;Gestione dell'informazione&quot; del corso di laurea triennale in informatica
di Unimore.
Verranno quindi riportati gli approfondimenti / chiarimenti che vengono
fatti durante le lezioni. Il materiale non è sostitutivo alle slide.
</code></pre><p>→ Link per accedere al <code>materiale didattico</code>:
<a href="https://moodle.unimore.it/course/view.php?id=7287">https://moodle.unimore.it/course/view.php?id=7287</a></p>
<hr>
<h2 id="ir--table-of-contents">(IR) TABLE OF CONTENTS<a href="#ir--table-of-contents" class="hanchor" ariaLabel="Anchor">&#8983;</a> </h2>
<ul>
<li><a href="#text-operations">Text Operations</a></li>
</ul>
<hr>
<h2 id="text-operations">Text Operations<a href="#text-operations" class="hanchor" ariaLabel="Anchor">&#8983;</a> </h2>
<h3 id="document-processing">Document Processing<a href="#document-processing" class="hanchor" ariaLabel="Anchor">&#8983;</a> </h3>
<ul>
<li>
<p><strong><code>Analisi lessicale</code></strong>: si converte una sequenza di caratteri in una sequenza
di token, dei potenziali canditati per dei termini &ldquo;index&rdquo;.</p>
</li>
<li>
<p><strong><code>Eliminazione delle stopwords</code></strong>: vengono eliminate quelle parole &ldquo;inutili&rdquo;
che non danno informazioni per la ricerca.</p>
</li>
<li>
<p><strong><code>Stemming e Lemmatization</code></strong>: esempio di uno <strong>stem</strong> &ndash;&gt; &lsquo;connect&rsquo; è lo stem
di parole come &lsquo;connected&rsquo;, &lsquo;connection&rsquo;, &lsquo;connecting&rsquo;. Lo <strong>stemmer</strong> è
il tool che si occupa della stemmization.</p>
<p>esempio di un <strong>lemma</strong> &ndash;&gt; &lsquo;see&rsquo; è il lemma per &lsquo;seen&rsquo; &lsquo;saw&rsquo;; Il <strong>lemmatizer</strong>
si occupa della generazione dei lemma.</p>
<p>Esistono alcuni parametri per giudicare uno stemmer: (i) <strong>correttezza</strong>, (ii) <strong>efficacia</strong>,
(iii) miglioramento della <strong>performance</strong>.</p>
</li>
<li>
<p><strong><code>Selezione degli Index</code></strong> in pratica vengono scelti i token più
significativi. Può essere fatta manualmente (da esperti) oppure automaticamente.
Esempio: &ldquo;Say&rdquo; &ldquo;Chair&rdquo; &ldquo;Be&rdquo; &ldquo;Enough&rdquo; &ndash;&gt; &ldquo;Chair&rdquo;</p>
</li>
<li>
<p><strong><code>Parsing</code></strong>: processo di analizzare uno stream di dati input e verificare la sua
correttezza sintattica. Questi strumenti (detti parser) lavorano sulla base
di &ldquo;banche dati&rdquo; usando un approccio statistico.</p>
</li>
<li>
<p><strong><code>Tagging</code></strong>: processo che assegna alle parole il loro ruolo all&rsquo;interno della frase.</p>
</li>
</ul>
<p>(Verbo, Nome, Aggettivo, ecc&hellip;)</p>
<h3 id="thesauri">Thesauri<a href="#thesauri" class="hanchor" ariaLabel="Anchor">&#8983;</a> </h3>
<p>Un <strong>Thesaurus</strong> è una lista di parole (sinonimi e contrari) importanti in un dato domain di conoscenza.
Ad esempio, in ambito medico, alla parola &ldquo;hand&rdquo; potrebbero essere collegati concetti
come &ldquo;sanityzers&rdquo;, &ldquo;transplantation&rdquo;, ecc..
A livello strutturale sono quindi dei <em>dizionari</em> che contengono associazioni.</p>
<h3 id="python-nltk-the-basics">Python NLTK, the basics<a href="#python-nltk-the-basics" class="hanchor" ariaLabel="Anchor">&#8983;</a> </h3>
<p>In questo script vengono trattati i seguenti argomenti:
(i) Generazione dei token, (ii) Rimozione delle stopwords, (iii) Lemmatizzazione,
(iv) Stemming, (v) Tagging.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">import</span> nltk
<span style="color:#f92672">from</span> nltk.corpus <span style="color:#f92672">import</span> stopwords
<span style="color:#f92672">from</span> nltk.stem.porter <span style="color:#f92672">import</span> PorterStemmer
<span style="color:#f92672">from</span> nltk.stem.lancaster <span style="color:#f92672">import</span> LancasterStemmer

text <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;This is a tests&#34;</span>
tokens <span style="color:#f92672">=</span> nltk<span style="color:#f92672">.</span>word_tokenize(text)
<span style="color:#66d9ef">print</span>(tokens)

<span style="color:#75715e"># Stopwords removal and Lemmatization</span>
wnl <span style="color:#f92672">=</span> nltk<span style="color:#f92672">.</span>WordNetLemmatizer()
<span style="color:#75715e"># per stampare tutte le parole che non sono stopwords.</span>
<span style="color:#66d9ef">for</span> t <span style="color:#f92672">in</span> tokens:
    <span style="color:#66d9ef">if</span> <span style="color:#f92672">not</span> t <span style="color:#f92672">in</span> stopwords<span style="color:#f92672">.</span>words(<span style="color:#e6db74">&#39;english&#39;</span>):
	<span style="color:#66d9ef">print</span>(wnl<span style="color:#f92672">.</span>lemmatize(t))

<span style="color:#75715e"># --&gt; [&#39;This&#39;, &#39;is&#39;, &#39;a&#39;, &#39;tests&#39;]</span>
<span style="color:#75715e">#     This</span>
<span style="color:#75715e">#     test</span>


<span style="color:#75715e"># Stemming, using Porter and Lancaster, two popular stemmers</span>
<span style="color:#75715e"># They give the same output for easy input</span>
porter <span style="color:#f92672">=</span> PorterStemmer()
<span style="color:#66d9ef">print</span>([porter<span style="color:#f92672">.</span>stem(t) <span style="color:#66d9ef">for</span> t <span style="color:#f92672">in</span> tokens])

lancaster <span style="color:#f92672">=</span> LancasterStemmer()
<span style="color:#66d9ef">print</span>([lancaster<span style="color:#f92672">.</span>stem(t) <span style="color:#66d9ef">for</span> t <span style="color:#f92672">in</span> tokens])

<span style="color:#75715e"># POS tagging a list of lemmatizen tokens!</span>
<span style="color:#66d9ef">print</span>([nltk<span style="color:#f92672">.</span>pos_tag([wnl<span style="color:#f92672">.</span>lemmatize(t) <span style="color:#66d9ef">for</span> t <span style="color:#f92672">in</span> tokens])])
<span style="color:#75715e"># --&gt; [[(&#39;This&#39;, &#39;DT&#39;), (&#39;is&#39;, &#39;VBZ&#39;), (&#39;a&#39;, &#39;DT&#39;), (&#39;test&#39;, &#39;NN&#39;)]]</span>
</code></pre></div><p><strong>Esercizio 1:</strong></p>
<p>eseguire le seguenti operazioni: (i)Tokenization, (ii)Elimination of stopwords, (iii)Stemming, (iv) Selection of nouns
su un file .txt contenente un libro di testo.
In questo caso ho scaricato una copia locale del file, per semplicità.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">import</span> nltk
<span style="color:#f92672">from</span> nltk.corpus <span style="color:#f92672">import</span> stopwords
<span style="color:#f92672">from</span> nltk.stem.porter <span style="color:#f92672">import</span> PorterStemmer

path <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;./book.txt&#34;</span>
file <span style="color:#f92672">=</span> open(path)
raw <span style="color:#f92672">=</span> file<span style="color:#f92672">.</span>read()
<span style="color:#66d9ef">print</span>(len(raw))

<span style="color:#75715e">#step1: tokenization</span>
tokens <span style="color:#f92672">=</span> nltk<span style="color:#f92672">.</span>word_tokenize(raw)
<span style="color:#66d9ef">print</span>(tokens[:<span style="color:#ae81ff">20</span>])

<span style="color:#75715e">#step2: eliminate stopwords</span>
no_stop_tokens <span style="color:#f92672">=</span> [t <span style="color:#66d9ef">for</span> t <span style="color:#f92672">in</span> tokens <span style="color:#66d9ef">if</span> <span style="color:#f92672">not</span> t <span style="color:#f92672">in</span> stopwords<span style="color:#f92672">.</span>words(<span style="color:#e6db74">&#39;english&#39;</span>)]
<span style="color:#66d9ef">print</span>(len(no_stop_tokens))

<span style="color:#75715e">#step3: stemming</span>
porter <span style="color:#f92672">=</span> PorterStemmer()
stemmed_tokens <span style="color:#f92672">=</span> ([porter<span style="color:#f92672">.</span>stem(t) <span style="color:#66d9ef">for</span> t <span style="color:#f92672">in</span> no_stop_tokens])

<span style="color:#75715e">#step4: get nouns thanks to tagging</span>
tagged_tokens <span style="color:#f92672">=</span> (nltk<span style="color:#f92672">.</span>pos_tag([t <span style="color:#66d9ef">for</span> t <span style="color:#f92672">in</span> stemmed_tokens]))
<span style="color:#66d9ef">print</span>(tagged_tokens[:<span style="color:#ae81ff">20</span>])
nouns <span style="color:#f92672">=</span> [t[<span style="color:#ae81ff">0</span>] <span style="color:#66d9ef">for</span> t <span style="color:#f92672">in</span> tagged_tokens <span style="color:#66d9ef">if</span> t[<span style="color:#ae81ff">1</span>] <span style="color:#f92672">==</span> <span style="color:#e6db74">&#39;NN&#39;</span>]
<span style="color:#66d9ef">print</span>(nouns[:<span style="color:#ae81ff">20</span>])
</code></pre></div><h3 id="wordnet--thesaurus">Wordnet (Thesaurus)<a href="#wordnet--thesaurus" class="hanchor" ariaLabel="Anchor">&#8983;</a> </h3>
<p><code>Synset</code> &ndash;&gt; concetto, può essere rappresentato da più parole.
In un generico thesaurus sono chiamati <em>Thesaurus Index Term</em>.</p>

  <figure class="left" >
    <img src="/ox-hugo/thes.png"   />
    
  </figure>


<p>Wordnet mette a disposizione una serie di relazioni tra i synset,
come i seguenti:</p>

  <figure class="left" >
    <img src="/ox-hugo/relazioni.png"   />
    
  </figure>


<p>La relazioni solitamente più usate sono <strong>Hypernymy</strong> e <strong>Meronymy</strong>.
Usare un thesaurus non è sempre una scelta corretta. In
un search engine generico come google non ha senso, dato che il
grafo delle relazioni diventerebbe enorme senza portare grossi benefici.
Al contrario è molto utile in casi specifici (e.g. search engine per
paper in ambito medico).</p>
<h3 id="word-similarities">Word similarities<a href="#word-similarities" class="hanchor" ariaLabel="Anchor">&#8983;</a> </h3>
<p><strong><code>sinonimia</code></strong> &ndash;&gt; relazione binaria che lega due parole attraverso
il significato.</p>
<p><strong><code>similarità o distanza</code></strong> &ndash;&gt; metrica più &ldquo;loose&rdquo; per dare un gradiente
di similarità.</p>
<p>Queste relazioni non vanno confuse con le relazioni del thesaurus.
Ad esempio benzina e macchina potrebbero essere collegate nel thesaurus
ma potrebbero anche non essere sinonimi!</p>
<p>Come misurare la similarità tra concetti? (<em>i</em>)path based (<em>ii</em>)information content measures.</p>
<ul>
<li><strong>Path based</strong>: sfrutto la gerarchia di ipernimia per stabilire il &ldquo;livello&rdquo; di
somiglianza di due concetti. Esistono principalmente 2 formule per effettuare
il calcolo (vedi figura 2).</li>
</ul>

  <figure class="left" >
    <img src="/ox-hugo/pathdistance.png"   />
    
      <figcaption class="center" ><span class="figure-number">Figure 1: </span>Path based similarities</figcaption>
    
  </figure>



  <figure class="left" >
    <img src="/ox-hugo/pathbased.png"   />
    
      <figcaption class="center" ><span class="figure-number">Figure 2: </span>Formule per il calcolo di similitudine (path based)</figcaption>
    
  </figure>


<p>Il problema della prima formula è che è molto discontinua
e genera dei valori non ben distribuiti. Questo problema
viene risolto da Wu-Palmer con la loro formula.
Per chiarezza, LCS &ndash;&gt; Least Common Subsumer.</p>
<ul>
<li><strong>Information content mesaures</strong>: quanto spesso questi
concetti vengono usati nello stesso contesto.
Dato un concetto, definisco con P(c) la probabilità
che scelta una parola a caso  in un corpus rappresenti
il determinato concetto.</li>
</ul>

  <figure class="left" >
    <img src="/ox-hugo/pc.png"   />
    
  </figure>


<p>Similarità di <strong><code>Resnik</code></strong>: calcolo l&rsquo;information content del
least common subsumer.</p>
<p>\begin{equation}
sim_{resnik}(c_{1}, c_{2}) = -log(P(LCS(c1,c2)))
\end{equation}</p>
<h3 id="word-sense-disambiguation">Word Sense disambiguation<a href="#word-sense-disambiguation" class="hanchor" ariaLabel="Anchor">&#8983;</a> </h3>
<p>La WSD consiste essenzialmente nell&rsquo;assegnare il senso corretto ad ogni
istanza di una certa parola di interesse.</p>
<ol>
<li>Determinare tutti i sensi che quella parola può assumere: abbastanza
automatico usando un thesaurus;</li>
<li>Analizzare il contesto dove la parola compare.
<ul>
<li><strong>Bag of words</strong>: il <em>contesto</em> è rappresentato da un pool di parole
&ldquo;vicine&rdquo; al termine di interesse che vengono estratte.</li>
<li><strong>Relational information:</strong> approccio più complesso che estrae altri
parametri come la distanza.</li>
</ul>
</li>
</ol>
<p>Ecco un&rsquo;approccio per implementare il tutto:</p>
<pre><code class="language-example" data-lang="example">for each noun N, for each sense Sn of N:
  compute confidence Csn in choosing sn as sense of N
select sense with higher confidence
</code></pre><p>Ora la domanda è: come calcolo la <code>confidence</code> \(C_{s_{n}}\) ?</p>
<p>\(\rightarrow\) mi baso sulla similarità tra \(s_{n}\) e tutti gli altri sensi delle parole
nel contesto! Poi per calcolare la similitudine posso usare tecniche come la <em>path-based</em>,
già discussa in precedenza.</p>
<p>Ricapitolando, ecco lo pseudocodice dell&rsquo;algoritmo:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">max_confidence <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
<span style="color:#66d9ef">for</span> each Si synset di I:
  confidence <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
  <span style="color:#66d9ef">for</span> each J term <span style="color:#f92672">in</span> context:
    max <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
    <span style="color:#66d9ef">for</span> each Sj synset of J:
      similarity <span style="color:#f92672">=</span> simil(Sj, Si)
      <span style="color:#66d9ef">if</span>(similarity <span style="color:#f92672">&gt;</span> max):
	max <span style="color:#f92672">=</span> similarity
    confidence <span style="color:#f92672">+=</span> max
  <span style="color:#66d9ef">if</span>(confidence <span style="color:#f92672">&gt;</span> max_confidence):
    max_confidence <span style="color:#f92672">=</span> confidence
pick(synseth_with_confidence(max_confidence))
</code></pre></div><p>Codice effettivo di un semplice word sense disambiguator in python:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">disambiguateTerms</span>(terms):
  <span style="color:#66d9ef">for</span> t_i <span style="color:#f92672">in</span> terms: <span style="color:#75715e"># t_i is target term</span>
    selSense <span style="color:#f92672">=</span> None
    selScore <span style="color:#f92672">=</span> <span style="color:#ae81ff">0.0</span>
    <span style="color:#66d9ef">for</span> s_ti <span style="color:#f92672">in</span> wn<span style="color:#f92672">.</span>synsets(t_i, wn<span style="color:#f92672">.</span>NOUN):
      score_i <span style="color:#f92672">=</span> <span style="color:#ae81ff">0.0</span>
      <span style="color:#66d9ef">for</span> t_j <span style="color:#f92672">in</span> terms: <span style="color:#75715e"># t_j term in t_i&#39;s context window</span>
	<span style="color:#66d9ef">if</span> (t_i<span style="color:#f92672">==</span>t_j):
	<span style="color:#66d9ef">continue</span>
      bestScore <span style="color:#f92672">=</span> <span style="color:#ae81ff">0.0</span>
	<span style="color:#66d9ef">for</span> s_tj <span style="color:#f92672">in</span> wn<span style="color:#f92672">.</span>synsets(t_j, wn<span style="color:#f92672">.</span>NOUN):
	  tempScore <span style="color:#f92672">=</span> s_ti<span style="color:#f92672">.</span>wup_similarity(s_tj)
	  <span style="color:#66d9ef">if</span> (tempScore<span style="color:#f92672">&gt;</span>bestScore):
	    bestScore<span style="color:#f92672">=</span>tempScore
	score_i <span style="color:#f92672">=</span> score_i <span style="color:#f92672">+</span> bestScore
      <span style="color:#66d9ef">if</span> (score_i<span style="color:#f92672">&gt;</span>selScore):
	selScore <span style="color:#f92672">=</span> score_i
	selSense <span style="color:#f92672">=</span> s_ti
    <span style="color:#66d9ef">if</span> (selSense <span style="color:#f92672">is</span> <span style="color:#f92672">not</span> None):
      <span style="color:#66d9ef">print</span>(t_i,<span style="color:#e6db74">&#34;: &#34;</span>,selSense,<span style="color:#e6db74">&#34;, &#34;</span>,selSense<span style="color:#f92672">.</span>definition())
      <span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#34;Score: &#34;</span>,selScore)
    <span style="color:#66d9ef">else</span>:
      <span style="color:#66d9ef">print</span>(t_i,<span style="color:#e6db74">&#34;: --&#34;</span>)
</code></pre></div>
      </div></div>

  

  
  

  
</div>

  </div>

  
    <footer class="footer">
  <div class="footer__inner">
    
      <div class="copyright">
        <span>© 2022 Powered by <a href="http://gohugo.io">Hugo</a></span>
    
        <span>:: Theme made by <a href="https://twitter.com/panr">panr</a></span>
      </div>
  </div>
</footer>

<script src="/assets/main.js"></script>
<script src="/assets/prism.js"></script>







  
</div>

</body>
</html>
